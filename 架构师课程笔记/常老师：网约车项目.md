# Eureka

通过ConcurrentHashMap来维护服务列表的

map<服务名，map<实例id，实例信息>>

```
ConcurrentHashMap<String, Map<String, Lease<InstanceInfo>>>
```

## eureka为什么是ap

- Eureka： **符合AP原则** 为了保证了可用性，`Eureka` 不会等待集群所有节点都已同步信息完成，它会无时无刻提供服务。
- Zookeeper： **符合CP原则** 为了保证一致性，在所有节点同步完成之前是阻塞状态的。





## 为什么加一个@EnableEurekaServer注解就可以运行

1. spring-cloud-netflix-eureka-server\2.2.2.RELEASE\spring-cloud-netflix-eureka-server-2.2.2.RELEASE.jar!\META-INF\spring.factories中导入了扫包配置

   ```
   org.springframework.boot.autoconfigure.EnableAutoConfiguration=\
   org.springframework.cloud.netflix.eureka.server.EurekaServerAutoConfiguration
   ```

   目的是将包内的EurekaServerAutoConfiguration类中的Bean注入到IOC容器中,但是类有@ConditionalOnBean({Marker.class})注解,需要Marker类在IOC容器中才注入,看第二步

2. 我们在启动文件上加上@EnableEurekaServer,这个注解的作用点进去看就是就是将Marker类注入到IOC中, 由此就将EurekaServerAutoConfiguration的Bean 注入到IOC了





## 优化点

### 自我保护阈值
```
  server:
  	# 自我保护，看服务多少。
    enable-self-preservation: false
    # 自我保护阈值
    renewal-percent-threshold: 0.85
    # 剔除服务时间间隔
    eviction-interval-timer-in-ms: 1000
    # 关闭从readOnly读注册表, 原因是readOnlyResponseCache和readWrite不是强同步的,ap的提现
    use-read-only-response-cache: false
    # readWrite 和 readOnly 同步时间间隔。提高服务被发现的速度
    response-cache-update-interval-ms: 1000
```


如果微服务少的话就不要开自我保护了,原因是

微服务少的话就开自我保护,原因是可能因为网络抖动导致部分服务

readWriteCacheMap

readOnlyCacheMap





生产中的问题: 

1. 优化目的: 减少服务上下线的延时
2. 自我保护的选择: 看网络和服务情况
3. 服务更新: 停止服务, 再发送下线请求

eureka-client配置总结

刷新注册表(拉去注册表)间隔

心跳间隔饥饿加载, 防止第一次请求超时

service-url: 打乱配置, 不要所有服务都写一样顺序的配置





加快服务发现速度, ap (三级缓存, 集群间同步)

加快服务过期剔除速度

自我保护

### 三级缓存





### 常用配置

eureka-server要把所有的其他eureka-server配上

```
eureka:
  instance:
    instance-id: xxxxx # 指定当前客户端在注册中心的名称
  client:
    register-with-eureka: true/false  # 是否向注册中心注册自己    
    fetch-registry: # 指定此客户端是否能获取eureka注册信息    
    service-url:    # 暴露服务中心地址      
      defaultZone: http://${eureka.instance.hostname}:${server.port}/eureka
```

```
eureka:  
  instance:
    hostname: xxxxx    # 主机名称    
    prefer-ip-address: true/false   # 注册时显示ip  
  server:    
    enableSelfPreservation: true   # 启动自我保护    
    renewalPercentThreshold: 0.85  # 续约配置百分比
    eviction-interval-timer-in-ms: 1000
    # 关闭从readOnly读注册表, 原因是readOnlyResponseCache和readWrite不是强同步的,ap的提现
    use-read-only-response-cache: false
    # readWrite 和 readOnly 同步时间间隔。提高服务被发现的速度
    response-cache-update-interval-ms: 1000
```

# 网关

## [Gateway 简介](http://www.macrozheng.com/#/cloud/gateway?id=gateway-简介)

Gateway是在Spring生态系统之上构建的API网关服务，基于Spring 5，Spring Boot 2和 Project Reactor等技术。Gateway旨在提供一种简单而有效的方式来对API进行路由，以及提供一些强大的过滤器功能， 例如：熔断、限流、重试等。

Spring Cloud Gateway 具有如下特性：

- 基于Spring Framework 5, Project Reactor 和 Spring Boot 2.0 进行构建；
- 动态路由：能够匹配任何请求属性；
- 可以对路由指定 Predicate（断言）和 Filter（过滤器）；
- 集成Hystrix的断路器功能；
- 集成 Spring Cloud 服务发现功能；
- 易于编写的 Predicate（断言）和 Filter（过滤器）；
- 请求限流功能；
- 支持路径重写。

## [相关概念](http://www.macrozheng.com/#/cloud/gateway?id=相关概念)

- Route（路由）：路由是构建网关的基本模块，它由ID，目标URI，一系列的断言和过滤器组成，如果断言为true则匹配该路由；
- Predicate（断言）：指的是Java 8 的 Function Predicate。 输入类型是Spring框架中的ServerWebExchange。 这使开发人员**可以匹配HTTP请求中的所有内容，例如请求头或请求参数。如果请求与断言相匹配，则进行路由**；
- Filter（过滤器）：指的是Spring框架中GatewayFilter的实例，使用过滤器，可以在请求被路由前后对请求进行修改。

### 路由

过滤与断言

```java
      routes:
        - id: product_route
          uri: lb://gulimall-product
          predicates:# 断言: 将匹配url: /api/product/** 路由到/gulimall-product/api/product/**
            - Path=/api/product/**
          filters:# 过滤器: 改写url请求路径 将/gulimall-product/api/product/**改写为/gulimall-product/product/**
            - RewritePath=/api/(?<segment>.*),/$\{segment}
```





## zuul



### zuul约等于 一系列的过滤器

- pre：在请求被路由到目标服务前执行，比如权限校验、打印日志等功能；
- routing：在请求被路由到目标服务时执行，这是使用Apache HttpClient或Netflix Ribbon构建和发送原始HTTP请求的地方；
- post：在请求被路由到目标服务后执行，比如给目标服务的响应添加头信息，收集统计数据等功能；
- error：请求在其他阶段发生错误时执行。







### zuul生产中的问题: 

1. token和cookie经过网关不向后传了

   一般不传过去, 但是可以实现传过去->zuul.sensitive-headers配置

2. 原来的url不改, 现在服务中心没有提供该url的接口, 但是有这个功能的接口, 只是url不一致, 如何用zuul来解决该问题

   比如: 原url是......com/test/userInfo, 现url是....com/test/xxxx/userInfo

   1. filter使用灰度的方式该url, 做好老url和新url的对应关系. 
   2. zuul自定义filter
   3. NGINX(地址映射)

   ```yaml
   zuul:
     routes:
       xxx:
         path: /api/**
         url: forward:/local
   ```

   当我们想在访问 api/1 的时候会路由到本地的 local/1 上去

3. 动态路由(根据不同用户路由到不同服务)

### zuul常用配置

```yaml
zuul:
  routes: #给服务配置路由
    user-service:
      path: /userService/**
    feign-service:
      path: /feignService/**
  ignored-services: user-service,feign-service #关闭默认路由配置
  prefix: /proxy #给网关路由添加前缀
  sensitive-headers: Cookie,Set-Cookie,Authorization #配置过滤敏感的请求头信息，设置为空就不会过滤
  add-host-header: true #设置为true重定向是会添加host请求头
  retryable: true # 关闭重试机制
  PreLogFilter:
    pre:
      disable: false #控制是否启用过滤器
```

### [核心过滤器](http://www.macrozheng.com/#/cloud/zuul?id=核心过滤器)

| 过滤器名称              | 过滤类型 | 优先级 | 过滤器的作用                                                 |
| ----------------------- | -------- | ------ | ------------------------------------------------------------ |
| ServletDetectionFilter  | pre      | -3     | 检测当前请求是通过DispatcherServlet处理运行的还是ZuulServlet运行处理的。 |
| Servlet30WrapperFilter  | pre      | -2     | 对原始的HttpServletRequest进行包装。                         |
| FormBodyWrapperFilter   | pre      | -1     | 将Content-Type为application/x-www-form-urlencoded或multipart/form-data的请求包装成FormBodyRequestWrapper对象。 |
| DebugFilter             | route    | 1      | 根据zuul.debug.request的配置来决定是否打印debug日志。        |
| PreDecorationFilter     | route    | 5      | 对当前请求进行预处理以便执行后续操作。                       |
| RibbonRoutingFilter     | route    | 10     | 通过Ribbon和Hystrix来向服务实例发起请求，并将请求结果进行返回。 |
| SimpleHostRoutingFilter | route    | 100    | 只对请求上下文中有routeHost参数的进行处理，直接使用HttpClient向routeHost对应的物理地址进行转发。 |
| SendForwardFilter       | route    | 500    | 只对请求上下文中有forward.to参数的进行处理，进行本地跳转。   |
| SendErrorFilter         | post     | 0      | 当其他过滤器内部发生异常时的会由它来进行处理，产生错误响应。 |
| SendResponseFilter      | post     | 1000   | 利用请求上下文的响应信息来组织请求成功的响应内容。           |

### 过滤器的使用

```java
@Component
public class PreLogFilter extends ZuulFilter {
    private Logger LOGGER = LoggerFactory.getLogger(this.getClass());

    /**
     * 过滤器类型，有pre、routing、post、error四种。
     */
    @Override
    public String filterType() {
        return "pre";
    }

    /**
     * 过滤器执行顺序，数值越小优先级越高。
     */
    @Override
    public int filterOrder() {
        return 1;
    }

    /**
     * 是否进行过滤，返回true会执行过滤。
     */
    @Override
    public boolean shouldFilter() {
        return true;
    }

    /**
     * 自定义的过滤器逻辑，当shouldFilter()返回true时会执行。
     */
    @Override
    public Object run() throws ZuulException {
        RequestContext requestContext = RequestContext.getCurrentContext();
        HttpServletRequest request = requestContext.getRequest();
        String host = request.getRemoteHost();
        String method = request.getMethod();
        String uri = request.getRequestURI();
        LOGGER.info("Remote host:{},method:{},uri:{}", host, method, uri);
        return null;
    }
}
```

### 经典动态路由问题解决的两种方式



### Actuator(监控功能)

```xml
<dependency>
    <groupId>org.springframework.boot</groupId>
    <artifactId>spring-boot-starter-actuator</artifactId>
</dependency>
```

```yaml
management:
  endpoints:
    web:
      exposure:
        include: "*"
  endpoint:
    health:
      ##默认是never
      show-details: ALWAYS
      enabled: true
    routes:
      enabled: true
```



http://localhost:8201/actuator/routes

http://localhost:8201/actuator/filters





## 网关找不到服务返回

```java
@Component
public class MsbFallback implements FallbackProvider {
    @Override
    public String getRoute() {
        return "*";
    }
    @Override
    public ClientHttpResponse fallbackResponse(String route, Throwable cause) {
        return new ClientHttpResponse() {
            @Override
            public HttpStatus getStatusCode() throws IOException {
                return HttpStatus.BAD_REQUEST;
            }

            @Override
            public int getRawStatusCode() throws IOException {
                return HttpStatus.BAD_REQUEST.value();
            }

            @Override
            public String getStatusText() throws IOException {
                return "message";
            }

            @Override
            public void close() {

            }

            @Override
            public InputStream getBody() throws IOException {
//                return new ByteArrayInputStream(JSONObject.fromObject(ResponseResult.fail(-1, "找不到服务")));
            }

            @Override
            public HttpHeaders getHeaders() {
                HttpHeaders headers = new HttpHeaders();
                headers.setContentType(MediaType.APPLICATION_JSON);
                return headers;
            }
        };
    }
}
```



## 限流

zuul网关限流

```java
@Component
public class LimitFilter extends ZuulFilter {
    //每秒2个; 0.1 = 10秒1个
    private static final RateLimiter RATE_LIMITER = RateLimiter.create(2);

    @Override
    public String filterType() {
        return FilterConstants.PRE_TYPE;
    }

    @Override
    public int filterOrder() {
        return -10;
    }

    @Override
    public boolean shouldFilter() {
        return true;
    }

    @Override
    public Object run() throws ZuulException {
        RequestContext currentContext = RequestContext.getCurrentContext();

        if(RATE_LIMITER.tryAcquire()){
            return null;
        }else{
            currentContext.set("limit", false);
            currentContext.setSendZuulResponse(false);
            currentContext.setResponseStatusCode(HttpStatus.TOO_MANY_REQUESTS.value());
        }
        return null;
    }
}
```

服务限流

```java
import com.google.common.util.concurrent.RateLimiter;

@Component
public class LimitFilter2 implements Filter {
    //每秒2个; 0.1 = 10秒1个
    private static final RateLimiter RATE_LIMITER = RateLimiter.create(2);

    @Override
    public void doFilter(ServletRequest servletRequest, ServletResponse servletResponse, FilterChain filterChain) throws IOException, ServletException {
        if(RATE_LIMITER.tryAcquire()){
            filterChain.doFilter(servletRequest, servletResponse);
        }else{
            servletResponse.setCharacterEncoding("utf-8");
            servletResponse.setContentType("text/html; charset=utf-8");
            PrintWriter pw = servletResponse.getWriter();
            pw.write("先溜了");
            pw.close();
        }
    }
}
```



## [sentinel熔断与限流](http://www.macrozheng.com/#/cloud/sentinel)







# [遍历Map](https://mp.weixin.qq.com/s?__biz=MzU4ODI1MjA3NQ==&mid=2247493142&idx=2&sn=c1913fc71d79d0f29f7902adf5eb23cb&chksm=fddd30d2caaab9c4761f7323a192cceb2a7b0ecf8cd9b281b2acb6dd581958f5dc2d0f8bd283&mpshare=1&scene=1&srcid=1126Dvq0xm8hqbn5X51rvj3N&sharer_sharetime=1606389082086&sharer_shareid=08bbf6eb5b2cc4049c7c1ec5220f6fc3&key=cd8d71bf880842d5cc92c029a7a66dfec41d0de0d19e8e2fe981f02a1a0d36a2a578c516d083cf1d6d2409e5216ba08054077bd758501d4004332de641ba62c3fd975ffdd53b5d846d613ae06be6c24ccb5e7cca2b6a7a4493d6b9993714f7dcfa4bea763846ae986a278ce58832d2b5b36e60568fe899688c9cef85a73674de&ascene=1&uin=MTIzMjQ3OTA2MQ%3D%3D&devicetype=Windows+10+x64&version=6300002f&lang=zh_CN&exportkey=A8VIATDXLjyMnQLfuWE0hQY%3D&pass_ticket=SUgGTDpfFfTVVRsZFeL4GSfSCrhp6e6043XlfC4O50kls85gGmiDejdqKatGAQWE&wx_header=0)

```java
Map<Integer, String> map = new HashMap();
map.put(1, "Java");
map.put(2, "JDK");
map.put(3, "Spring Framework");
map.put(4, "MyBatis framework");
map.put(5, "Java中文社群");

//1.迭代器 EntrySet
Iterator<Map.Entry<Integer, String>> iterator = map.entrySet().iterator();
while (iterator.hasNext()) {
  Map.Entry<Integer, String> entry = iterator.next();
  System.out.print(entry.getKey());
  System.out.print(entry.getValue());
}
//2.迭代器 KeySet
Iterator<Integer> iterator = map.keySet().iterator();
while (iterator.hasNext()) {
    Integer key = iterator.next();
    System.out.print(key);
    System.out.print(map.get(key));
}
//3.ForEach EntrySet
for (Map.Entry<Integer, String> entry : map.entrySet()) {
    System.out.print(entry.getKey());
    System.out.print(entry.getValue());
}
//4.ForEach KeySet
for (Integer key : map.keySet()) {
    System.out.print(key);
    System.out.print(map.get(key));
}
//5.Lambda
map.forEach((key, value) -> {
    System.out.print(key);
    System.out.print(value);
});
//6.Streams API 单线程
map.entrySet().stream().forEach((entry) -> {
    System.out.print(entry.getKey());
    System.out.print(entry.getValue());
});
//7.Streams API 多线程
map.entrySet().parallelStream().forEach((entry) -> {
    System.out.print(entry.getKey());
    System.out.print(entry.getValue());
});
```

# [mybatis的高级应用](https://juejin.cn/post/6844904069010554894)

## 1. 关联查询

举例：因为一个订单信息只会是一个人下的订单，所以从查询订单信息出发，关联查询用户信息为一对一查询。如果从用户信息出发，查询用户下的订单信息则为一对多查询，因为一个用户可以下多个订单。

### 1.1 一对一查询 

#### 需求

查询所有订单信息，关联查询下单用户信息。

#### SQL语句

**主信息：订单表**

**从信息：用户表**

```mysql
SELECT 
  orders.*,
  user.username,
  user.address
FROM
  orders LEFT JOIN user 
  ON orders.user_id = user.id
复制代码
```

#### 方法一：resultType

返回resultType方式比较简单，也比较常用，就不做介绍了。

#### 方法二：resultMap

使用resultMap进行结果映射，定义专门的resultMap用于映射一对一查询结果。

##### 创建扩展po类

创建OrdersExt类（**该类用于结果集封装**），加入User属性，user属性中用于存储关联查询的用户信息，因为订单关联查询用户是一对一关系，所以这里使用单个User对象存储关联查询的用户信息。

```java
public class OrdersExt extends Orders {

    private User user;// 用户对象
    // get/set。。。。
}
复制代码
```

##### Mapper映射文件

在UserMapper.xml中，添加以下代码：

```xml
<!-- 查询订单关联用户信息使用resultmap -->
    <resultMap type="OrdersExt" id="ordersAndUserRstMap">
        <id column="id" property="id"/>
        <result column="user_id" property="userId"/>
        <result column="number" property="number"/>
        <result column="createtime" property="createtime"/>
        <result column="note" property="note"/>
        <!-- 一对一关联映射 -->
        <!-- 
        property:Orders对象的user属性
        javaType：user属性对应 的类型
         -->
        <association property="user" javaType="com.kkb.mybatis.po.User">
            <!-- column:user表的主键对应的列  property：user对象中id属性-->
            <id column="user_id" property="id"/>
            <result column="username" property="username"/>
            <result column="address" property="address"/>
        </association>
    </resultMap>
    <select id="findOrdersAndUserRstMap" resultMap="ordersAndUserRstMap">
        SELECT
            o.id,
            o.user_id,
            o.number,
            o.createtime,
            o.note,
            u.username,
            u.address
        FROM
            orders o
        JOIN `user` u ON u.id = o.user_id
    </select>
复制代码
```

- **association**：表示进行一对一关联查询映射
- **property**：表示关联查询的结果存储在com.kkb.mybatis.po.Orders的user属性中
- **javaType**：表示关联查询的映射结果类型

##### Mapper接口

在UserMapper接口中，添加以下接口方法：

```java
public List<OrdersExt> findOrdersAndUserRstMap() throws Exception;
复制代码
```

##### 测试代码

在UserMapperTest测试类中，添加测试代码：

```java
public void testfindOrdersAndUserRstMap()throws Exception{
        //获取session
        SqlSession session = sqlSessionFactory.openSession();
        //获限mapper接口实例
        UserMapper userMapper = session.getMapper(UserMapper.class);
        //查询订单信息
        List<OrdersExt> list = userMapper.findOrdersAndUserRstMap();
        System.out.println(list);
        //关闭session
        session.close();
    }
复制代码
```

##### 小结

使用resultMap进行结果映射时，具体是使用association完成关联查询的映射，将关联查询信息映射到pojo对象中。

### 1.2 一对多查询 

#### 需求

查询所有用户信息及用户关联的订单信息。

#### SQL语句

**主信息：用户信息**

**从信息：订单信息**

```mysql
SELECT
    u.*, 
    o.id oid,
    o.number,
    o.createtime,
    o.note
FROM
    `user` u
LEFT JOIN orders o ON u.id = o.user_id
复制代码
```

#### 分析

在一对多关联查询时，只能使用resultMap进行结果映射：

1、一对多关联查询时，sql查询结果有多条，而映射对象是一个。

2、resultType完成结果映射的方式的一条记录映射一个对象。

3、resultMap完成结果映射的方式是以[主信息]为主对象，[从信息]映射为集合或者对象，然后封装到主对象中。

#### 修改po类

在User类中加入List orders属性。 

#### Mapper映射文件

在UserMapper.xml文件中，添加以下代码：

```xml
<resultMap type="user" id="userAndOrderRstMap">
        <!-- 用户信息映射 -->
        <id property="id" column="id"/>
        <result property="username" column="username"/>
        <result property="birthday" column="birthday"/>
        <result property="sex" column="sex"/>
        <result property="address" column="address"/>
        <!-- 一对多关联映射 -->
        <collection property="orders" ofType="orders">
            <id property="id" column="oid"/>    
            <result property="userId" column="id"/>
            <result property="number" column="number"/>
            <result property="createtime" column="createtime"/>
            <result property="note" column="note"/>
        </collection>
    </resultMap>
    <select id="findUserAndOrderRstMap" resultMap="userAndOrderRstMap">
        SELECT
        u.*,
    o.id oid,
        o.number,
        o.createtime,
        o.note
        FROM
        `user` u
        LEFT JOIN orders o ON u.id = o.user_id
    </select>
复制代码
```

Collection标签：定义了一对多关联的结果映射。

- **property="orders"**：关联查询的结果集存储在User对象的上哪个属性。
- **ofType="orders"**：指定关联查询的结果集中的对象类型即List中的对象类型。此处可以使用别名，也可以使用全限定名。

#### Mapper接口

```java
// resultMap入门
public List<User> findUserAndOrdersRstMap() throws Exception; 
复制代码
```

#### 测试代码

```java
@Test
    public void testFindUserAndOrdersRstMap() {
        SqlSession session = sqlSessionFactory.openSession();
        UserMapper userMapper = session.getMapper(UserMapper.class);
        List<User> result = userMapper.findUserAndOrdersRstMap();
        for (User user : result) {
            System.out.println(user);
        }
        session.close();
    }
复制代码
```

## 2. 延迟加载

### 2.1 什么是延迟加载 

- MyBatis中的延迟加载，也称为**懒加载**，是指在进行关联查询时，按照设置延迟规则推迟对关联对象的select查询。延迟加载可以有效的减少数据库压力。
- Mybatis的延迟加载，需要通过**resultMap标签中的association和collection**子标签才能演示成功。
- Mybatis的延迟加载，也被称为是嵌套查询，对应的还有**嵌套结果**的概念，可以参考一对多关联的案例。
- 注意：**MyBatis的延迟加载只是对关联对象的查询有延迟设置，对于主加载对象都是直接执行查询语句的sql**。

### 2.2 延迟加载的分类 

MyBatis根据对关联对象查询的select语句的**执行时机**，分为三种类型：**直接加载、侵入式加载与深度延迟加载**

- **直接加载：** 执行完对主加载对象的select语句，马上执行对关联对象的select查询。
- **侵入式延迟**：执行对主加载对象的查询时，不会执行对关联对象的查询。但当要访问主加载对象的某个属性（该属性不是关联对象的属性）时，就会马上执行关联对象的select查询。
- **深度延迟：**执行对主加载对象的查询时，不会执行对关联对象的查询。访问主加载对象的详情时也不会执行关联对象的select查询。只有当真正访问关联对象的详情时，才会执行对关联对象的select查询。

> 延迟加载策略需要在Mybatis的全局配置文件中，通过标签进行设置。

### 2.3 案例准备 

查询订单信息及它的下单用户信息。

### 2.4 直接加载 

通过对全局参数：lazyLoadingEnabled进行设置，默认就是false。

```xml
<settings>
    <!-- 延迟加载总开关 -->
    <setting name="lazyLoadingEnabled" value="false"/>
</settings>
复制代码
```

### 2.5 侵入式延迟加载 

```xml
<settings>
    <!-- 延迟加载总开关 -->
    <setting name="lazyLoadingEnabled" value="true"/>
    <!-- 侵入式延迟加载开关 -->
    <setting name="aggressiveLazyLoading" value="true"/>
</settings>
复制代码
```

### 2.6 深度延迟加载 

```xml
<settings>
    <!-- 延迟加载总开关 -->
    <setting name="lazyLoadingEnabled" value="true"/>
    <!-- 侵入式延迟加载开关 -->
    <setting name="aggressiveLazyLoading" value="false"/>
</settings>
复制代码
```

### 2.7 N+1问题 

- 深度延迟加载的使用会提升性能。
- 如果延迟加载的表数据太多，此时会产生N+1问题，主信息加载一次算1次，而从信息是会根据主信息传递过来的条件，去查询从表多次。

## 3. 动态SQL

动态SQL的思想：就是使用不同的动态SQL标签去完成字符串的拼接处理、循环判断。

解决的问题是：

1. 在映射文件中，会编写很多有重叠部分的SQL语句，比如SELECT语句和WHERE语句等这些重叠语句，该如何处理
2. SQL语句中的where条件有多个，但是页面只传递过来一个条件参数，此时会发生问题。

### 3.1 if标签 

综合查询的案例中，查询条件是由页面传入，页面中的查询条件可能输入用户名称，也可能不输入用户名称。

```xml
    <select id="findUserList" parameterType="queryVo" resultType="user">
        SELECT * FROM user where 1=1
        <if test="user != null">
            <if test="user.username != null and user.username != ''">
                AND username like '%${user.username}%'
            </if>
        </if>
    </select>
复制代码
```

**注意：要做『不等于空』字符串校验。**

### 3.2 where标签 

上边的sql中的1=1，虽然可以保证sql语句的完整性：但是存在性能问题。Mybatis提供where标签解决该问题。

代码修改如下：

```xml
    <select id="findUserList" parameterType="queryVo" resultType="user">
        SELECT * FROM user
        <!-- where标签会处理它后面的第一个and -->
        <where>
            <if test="user != null">
                <if test="user.username != null and user.username != ''">
                    AND username like '%${user.username}%'
                </if>
            </if>
        </where>
    </select>
复制代码
```

### 3.3 sql片段 

在映射文件中可使用sql标签将重复的sql提取出来，然后使用include标签引用即可，最终达到sql重用的目的，具体实现如下：

- 原映射文件中的代码：

  ```xml
  <select id="findUserList" parameterType="queryVo" resultType="user">
        SELECT * FROM user
        <!-- where标签会处理它后面的第一个and -->
        <where>
            <if test="user != null">
                <if test="user.username != null and user.username != ''">
                    AND username like '%${user.username}%'
                </if>
            </if>           
        </where>
    </select>
  复制代码
  ```

- 将where条件抽取出来：

```xml
<sql id="query_user_where">
        <if test="user != null">
            <if test="user.username != null and user.username != ''">
                AND username like '%${user.username}%'
            </if>
        </if>
</sql>
复制代码
```

- 使用include引用：

```xml
    <!-- 使用包装类型查询用户 使用ognl从对象中取属性值，如果是包装对象可以使用.操作符来取内容部的属性 -->
    <select id="findUserList" parameterType="queryVo" resultType="user">
        SELECT * FROM user
        <!-- where标签会处理它后面的第一个and -->
        <where>
            <include refid="query_user_where"></include>
        </where>

    </select>
复制代码
```

**注意：**

**1、如果引用其它mapper.xml的sql片段，则在引用时需要加上namespace，如下：**

```
<include refid="namespace.sql片段”/>
复制代码
```

### 3.4 foreach 

#### 需求

综合查询时，传入多个id查询用户信息，用下边两个sql实现：

```
SELECT * FROM USER WHERE username LIKE '%老郭%' AND (id =1 OR id =10 OR id=16)

SELECT * FROM USER WHERE username LIKE '%老郭%'  AND  id  IN (1,10,16)
复制代码
```

#### POJO

在pojo中定义list属性ids存储多个用户id，并添加getter/setter方法

#### Mapper映射文件

```xml
<sql id="query_user_where">
        <if test="user != null">
            <if test="user.username != null and user.username != ''">
                AND username like '%${user.username}%'
            </if>
        </if>
        <if test="ids != null and ids.size() > 0">
            <!-- collection：指定输入的集合参数的参数名称 -->
            <!-- item：声明集合参数中的元素变量名 -->
            <!-- open：集合遍历时，需要拼接到遍历sql语句的前面 -->
            <!-- close：集合遍历时，需要拼接到遍历sql语句的后面 -->
            <!-- separator：集合遍历时，需要拼接到遍历sql语句之间的分隔符号 -->
            <foreach collection="ids" item="id" open=" AND id IN ( "
                close=" ) " separator=",">
                #{id}
            </foreach>
        </if>
    </sql>
复制代码
```

#### 测试代码

在UserMapperTest测试代码中，修改testFindUserList方法，如下：

```java
@Test
    public void testFindUserList() throws Exception {
        SqlSession sqlSession = sqlSessionFactory.openSession();
        // 获得mapper的代理对象
        UserMapper userMapper = sqlSession.getMapper(UserMapper.class);
        // 创建QueryVo对象
        QueryVo queryVo = new QueryVo();
        // 创建user对象
        User user = new User();
        user.setUsername("老郭");

        queryVo.setUser(user);

        List<Integer> ids = new ArrayList<Integer>();
        ids.add(1);// 查询id为1的用户
        ids.add(10); // 查询id为10的用户
        queryVo.setIds(ids);

        // 根据queryvo查询用户
        List<User> list = userMapper.findUserList(queryVo);
        System.out.println(list);
        sqlSession.close();
    }
复制代码
```

#### 注意事项

**如果parameterType不是POJO类型，而是List或者Array的话，那么foreach语句中，collection属性值需要固定写死为list或者array。**





# [Java 集合转换(数组、List、Set、Map相互转换)](https://blog.csdn.net/top_code/article/details/10552827)

```java
	private static void testMap2List() {
		
		Map<String, String> map = new HashMap<String, String>();  
        map.put("A", "ABC");  
        map.put("K", "KK");  
        map.put("L", "LV");  
        
		// 将Map Key 转化为List    
        List<String> mapKeyList = new ArrayList<String>(map.keySet());  
        System.out.println("mapKeyList:"+mapKeyList);
        
        // 将Map Key 转化为List    
        List<String> mapValuesList = new ArrayList<String>(map.values());  
        System.out.println("mapValuesList:"+mapValuesList);
        
	}
 
	private static void testMap2Set() {
		
        Map<String, String> map = new HashMap<String, String>();  
        map.put("A", "ABC");  
        map.put("K", "KK");  
        map.put("L", "LV");  
        
        // 将Map 的键转化为Set    
        Set<String> mapKeySet = map.keySet();  
        System.out.println("mapKeySet:"+mapKeySet);
        
        // 将Map 的值转化为Set    
        Set<String> mapValuesSet = new HashSet<String>(map.values());  
        System.out.println("mapValuesSet:"+mapValuesSet);
	}
 
	private static void testArray2Set() {
		
        String[] arr = {"AA","BB","DD","CC","BB"};  
        
        //数组-->Set  
        Set<String> set = new HashSet<String>(Arrays.asList(arr));  
        System.out.println(set);  
	}
 
	private static void testSet2Array() {
		Set<String> set = new HashSet<String>();
		set.add("AA");
		set.add("BB");
		set.add("CC");
		
		String[] arr = new String[set.size()];  
		//Set-->数组  
		set.toArray(arr); 
        System.out.println(Arrays.toString(arr));  
	}
 
	private static void testList2Set() {
		  
		List<String> list = new ArrayList<String>();
		list.add("ABC");
		list.add("EFG");
		list.add("LMN");
		list.add("LMN");
		
		//List-->Set
        Set<String> listSet = new HashSet<String>(list);
        System.out.println(listSet);
	}
 
	private static void testSet2List() {
		 
		Set<String> set = new HashSet<String>();
		set.add("AA");
		set.add("BB");
		set.add("CC");
		
		//Set --> List
        List<String> setList = new ArrayList<String>(set);
        System.out.println(setList);  
	}
 
	private static void testList2Array() {
		//List-->数组  
        List<String> list = new ArrayList<String>();  
        list.add("AA");  
        list.add("BB");  
        list.add("CC");  
        Object[] objects = list.toArray();//返回Object数组  
        System.out.println("objects:"+Arrays.toString(objects));  
        
        String[] arr = new String[list.size()];  
        list.toArray(arr);//将转化后的数组放入已经创建好的对象中  
        System.out.println("strings1:"+Arrays.toString(arr));  
	}
	
	private static void testArray2List() {
		//数组-->List  
        String[] ss = {"JJ","KK"};  
        List<String> list1 = Arrays.asList(ss);  
        List<String> list2 = Arrays.asList("AAA","BBB");  
        System.out.println(list1);  
        System.out.println(list2);  
	}
```



# MQ(消息中间件)

|            特性             |                      ActiveMQ                      |                           RabbitMQ                           |                           RocketMQ                           |                            Kafka                             |
| :-------------------------: | :------------------------------------------------: | :----------------------------------------------------------: | :----------------------------------------------------------: | :----------------------------------------------------------: |
|       **单机吞吐量**        |    万级，吞吐量比RocketMQ和Kafka要低一个数量级     |         万级，吞吐量比RocketMQ和Kafka要低一个数量级          |          十万级，RocketMQ也是可以支撑高吞吐的一种MQ          | 十万级别，Kafka最大优点就是吞吐量大，一般配合大数据类的系统来进行实时数据计算、日志采集等场景 |
| **Topic数量对吞吐量的影响** |                         -                          |                              -                               | Topic可以达到几百、几千个的级别，吞吐量会有小幅度的下降。这是RocketMQ的一大优势，可在同等数量机器下支撑大量的Topic | Topic从几十个到几百个的时候，吞吐量会大幅下降。所以在同等机器数量下，Kafka尽量保证Topic数量不要过多。如果支撑大规模Topic需要增加更多的机器 |
|         **时效性**          |                        ms级                        |         微秒级，这是rabbitmq的一大特点，延迟是最低的         |                             ms级                             |                        延迟在ms级以内                        |
|         **可用性**          |             高，基于主从架构实现可用性             |                  高，基于主从架构实现可用性                  |                      非常高，分布式架构                      | 非常高，Kafka是分布式的，一个数据多个副本，少数机器宕机，不会丢失数据，不会导致不可用 |
|       **消息可靠性**        |                有较低的概率丢失数据                |                              -                               |               经过参数优化配置，可以做到零丢失               |               经过参数配置，消息可以做到零丢失               |
|        **功能支持**         |                MQ领域的功能及其完备                |      基于erlang开发，所以并发性能极强，性能极好，延时低      |                MQ功能较为完备，分布式扩展性好                |               功能较为简单，主要支持加单MQ功能               |
|          **优势**           | 非常成熟，功能强大，在业内大量公司和项目中都有应用 | erlang语言开发，性能极好、延时很低，吞吐量万级、MQ功能完备，管理界面非常好，社区活跃；互联网公司使用较多 | 接口简单易用，阿里出品有保障，吞吐量大，分布式扩展方便、社区比较活跃，支持大规模的Topic、支持复杂的业务场景，可以基于源码进行定制开发 | 超高吞吐量，ms级的时延，极高的可用性和可靠性，分布式扩展方便 |
|          **劣势**           |       偶尔有较低概率丢失消息，社区活跃度不高       | 吞吐量较低，erlang语音开发不容易进行定制开发，集群动态扩展麻烦 | 接口不是按照标准JMS规范走的，有的系统迁移要修改大量的代码，技术有被抛弃的风险 |                   有可能进行消息的重复消费                   |
|          **应用**           |   主要用于解耦和异步，较少用在大规模吞吐的场景中   |                           都有使用                           |                  用于大规模吞吐、复杂业务中                  |   在大数据的实时计算和日志采集中被大规模使用，是业界的标准   |



# [json序列化](https://juejin.cn/post/6844903957353988103)

```java
/***
1. 对于不想进行序列化的变量，使用 transient 关键字修饰。
transient 关键字的作用是：阻止实例中那些用此关键字修饰的的变量序列化；当对象被反序列化时，被 transient 修饰的变量值不会被持久化和恢复。transient 只能修饰变量，不能修饰类和方法。
2. 
***/
//jackson
//Java对象序列化为Json
ObjectMapper objectMapper = new ObjectMapper();
Car car = new Car("yellow", "renault");
String carAsString = objectMapper.writeValueAsString(car);
//{"color":"yellow","type":"renault"}

//JSON反序列化为Java对象
ObjectMapper objectMapper = new ObjectMapper();
String json = "{ \"color\" : \"Black\", \"type\" : \"BMW\"}";
Car car = objectMapper.readValue(json, Car.class);
System.out.println(car);
//输出结果:Car(color=Black, type=BMW)

//JSON 反序列化为Jackson JsonNode
String json = "{ \"color\" : \"Black\", \"type\" : \"FIAT\" }";
JsonNode jsonNode = objectMapper.readTree(json);
String color = jsonNode.get("color").asText();
// Output: color -> Black


//JSON数组反序列化为Java List
String jsonCarArray = "[{ \"color\" : \"Black\", \"type\" : \"BMW\" },{ \"color\" : \"Red\", \"type\" : \"FIAT\" }]";
List<Car> listCar = objectMapper.readValue(jsonCarArray, new TypeReference<List<Car>>(){});
//[Car(color=Black, type=BMW), Car(color=Red, type=FIAT)]
System.out.println(listCar);

//JSON字符串反序列化为Java Map
String json = "{ \"color\" : \"Black\", \"type\" : \"BMW\" }";
Map<String, Object> map = objectMapper.readValue(json, new TypeReference<Map<String,Object>>(){});
//{color=Black, type=BMW}
System.out.println(map);

```

# [Optional对象使用](https://juejin.cn/post/6844904085980708871)

### 创建 Optional 对象

1）可以使用静态方法 `empty()` 创建一个空的 Optional 对象

```java
Optional<String> empty = Optional.empty();
System.out.println(empty); // 输出：Optional.empty
```

2）可以使用静态方法 `of()` 创建一个非空的 Optional 对象

```java
Optional<String> opt = Optional.of("沉默王二");
System.out.println(opt); // 输出：Optional[沉默王二]
```

当然了，传递给 `of()` 方法的参数必须是非空的，也就是说不能为 null，否则仍然会抛出 NullPointerException。

3）可以使用静态方法 `ofNullable()` 创建一个即可空又可非空的 Optional 对象

```java
String name = null;
Optional<String> optOrNull = Optional.ofNullable(name);
System.out.println(optOrNull); // 输出：Optional.empty
```

`ofNullable()` 方法内部有一个三元表达式，如果为参数为 null，则返回私有常量 EMPTY；否则使用 new 关键字创建了一个新的 Optional 对象——不会再抛出 NPE 异常了。

### 判断值是否存在

可以通过方法 `isPresent()` 判断一个 Optional 对象是否存在，如果存在，该方法返回 true，否则返回 false——取代了 `obj != null` 的判断。

```java
Optional<String> opt = Optional.of("沉默王二");
System.out.println(opt.isPresent()); // 输出：true

Optional<String> optOrNull = Optional.ofNullable(null);
System.out.println(opt.isPresent()); // 输出：false
```

### 非空表达式

有了 `ifPresent()` 之后，情况就完全不同了，可以直接将 Lambda 表达式传递给该方法，代码更加简洁，更加直观。

```java
Optional<String> opt = Optional.of("沉默王二");
opt.ifPresent(str -> System.out.println(str.length()));
```

Java 9 后还可以通过方法 `ifPresentOrElse(action, emptyAction)` 执行两种结果，非空时执行 action，空时执行 emptyAction。

```java
Optional<String> opt = Optional.of("沉默王二");
opt.ifPresentOrElse(str -> System.out.println(str.length()), () -> System.out.println("为空"));
```

### 设置（获取）默认值

`orElse()` 方法用于返回包裹在 Optional 对象中的值，如果该值不为 null，则返回；否则返回默认值。该方法的参数类型和值得类型一致。

```java
String nullName = null;
String name = Optional.ofNullable(nullName).orElse("沉默王二");
System.out.println(name); // 输出：沉默王二
```

`orElseGet()` 方法与 `orElse()` 方法类似，但参数类型不同。如果 Optional 对象中的值为 null，则执行参数中的函数。

```java
String nullName = null;
String name = Optional.ofNullable(nullName).orElseGet(()->"沉默王二");
System.out.println(name); // 输出：沉默王二
```

从输出结果以及代码的形式上来看，这两个方法极其相似，这不免引起我们的怀疑，Java 类库的设计者有必要这样做吗？

### 过滤值

```java
Predicate<String> len6 = pwd -> pwd.length() > 6;
Predicate<String> len10 = pwd -> pwd.length() < 10;

password = "1234567";
opt = Optional.ofNullable(password);
boolean result = opt.filter(len6.and(len10)).isPresent();
System.out.println(result);
复制代码
```

这次程序输出的结果为 true，因为密码变成了 7 位，在 6 到 10 位之间。想象一下，假如小王使用 if-else 来完成这个任务，代码该有多冗长。

### 转换值










**windowns查看端口占用情况与杀死进程**

```powershell
netstat -ano | findstr 8080
tasklist|findstr 8080 #查找对应进程名称
taskkill /f /pid 8080 #强制杀死端口进程
taskkill /f /t /im /javaw.exe #强制杀死进程
```





**生产中不要用0.0.1-SNAPSHOT快照版本 **

**常用的, 不变的, 用缓存, 不要去db , 提升QPS**

**瓶颈在IO, 网络, 磁盘IO, 减少IO**

**估算线程数:  线程数 = CPU可用核数 / 1 - 阻塞系数 (io密集型接近1, 计算密集型 接近0)**

提升QPS的办法: 

- 提高并发数
  - 能用多线程用多线程
  - 增加各种连接数 Tomcat, mysql, redis等
  -  服务无状态, 便于横向扩张(扩机器)
  - 让服务能力对等 ,也就是让服务负载对等

- 减少响应时间
  - 异步(保证一致性, 不需要及时), 流量削xue峰填谷
  - 缓存(减少db读取, 减少磁盘io, 读多, 写少)
  - 数据库优化
  - 多的数据, 分批次返回
  - 减少调用链(比如服务之间的调用)
  - 长连接场景的使用, 不要轮询

常用注解

```
@RestController
@RequestMapping("/test")
@RequestMapping(value = "/sms-template",method = RequestMethod.POST)
@Slf4j
@RequestBody
@PathVariable("identity") int identity , @PathVariable ("phoneNumber") String phoneNumber
@Validated
@Value("${server.port}")

@Service
@Component
@Mapper



/**
 * chain的中文含义是链式的，设置为true，则setter方法返回当前对象
 */
@Accessors(chain = true)

@ComponentScan(
        excludeFilters = {
        @ComponentScan.Filter(type = FilterType.ANNOTATION,value = ExcudeRibbonConfig.class)
})

@Bean


@Configuration
@ExcudeRibbonConfig


@Aspect
@Component
@Pointcut("execution(* com.mashibing.apipassenger.controller..*Controller*.*(..))")



```

将接受的参数映射为 自定义类: @RequestBody注解

验证自定义类的字段使用@Validated注解

```java
    public ResponseResult send(@RequestBody @Validated ShortMsgRequest request){
        return verificationCodeService.send(request.getPhoneNumber());
    }
```

> ```
> 验证字段注解
> @Pattern(message = "手机号校验不正确",regexp = "^((13[0-9])|(14[5,7,9])|(15([0-3]|[5-9]))|(166)|(17[0,1,3,5,6,7,8])|(18[0-9])|(19[8|9]))\\d{8
> @NotEmpty 被注释的字符串的不能为 null 也不能为空
> @NotBlank 被注释的字符串非 null，并且必须包含一个非空白字符
> @Null 被注释的元素必须为 null
> @NotNull 被注释的元素必须不为 null
> @AssertTrue 被注释的元素必须为 true
> @AssertFalse 被注释的元素必须为 false
> @Pattern(regex=,flag=)被注释的元素必须符合指定的正则表达式
> @Email 被注释的元素必须是 Email 格式。
> @Min(value)被注释的元素必须是一个数字，其值必须大于等于指定的最小值
> @Max(value)被注释的元素必须是一个数字，其值必须小于等于指定的最大值
> @DecimalMin(value)被注释的元素必须是一个数字，其值必须大于等于指定的最小值
> @DecimalMax(value) 被注释的元素必须是一个数字，其值必须小于等于指定的最大值
> @Size(max=, min=)被注释的元素的大小必须在指定的范围内
> @Digits (integer, fraction)被注释的元素必须是一个数字，其值必须在可接受的范围内
> @Past被注释的元素必须是一个过去的日期
> @Future 被注释的元素必须是一个将来的日期
> ```



RedisTemplate的使用

```java
@Autowired
private RedisTemplate<String, String> redisTemplate;
//存
BoundValueOperations<String, String> codeRedis = redisTemplate.boundValueOps(key);
codeRedis.set(code,2,TimeUnit.MINUTES);
//取
BoundValueOperations<String, String> codeRedis = redisTemplate.boundValueOps(key);
        String redisCode = codeRedis.get();
```





服务间调用使用RestTemplate

```java
    @LoadBalanced
    @Bean
    public RestTemplate restTemplate(){
        return new RestTemplate();
    }
```



每个功能都抽取流程和需要的数据, 根据这两个东西进行抽象,编码, 



# 登录

1. 发送手机验证码
2. 校验验证码
3. 根据手机号查询用户信息
4. 用户不存在
   1. 新增用户
   2. 新增注册来源
   3. 初始化用户钱包
5. 生成access_token, 并缓存到redis
6. 多终端互踢
7. 返回access_token和用户信息, 登录成功





生成短信验证码不要这样写

```java
String code = String.valueOf(new Random().nextInt(1000000));//会出现小于6位的情况

String code = (Math.random()+"").substring(2,8);//随机获得的是[0,1)的值, 再截取2到8位的数字, 这样效率很低,下面的方法差不多是这个的10倍速度

String code = String.valueOf((int)((Math.random()*9+1)*Math.pow(10,5)));//推荐,因为是纯数字的操作
```

限制规则

- 一档
  - 限制: 1小时内非连续相同验证码错误达3次后,限制10分钟后登录
  - 注意: 从第一次点击登录开始计时
  - toast: "您登陆失败的次数过得多, 请10分钟后再想重试"
- 二挡
  - 限制: 1小时内非连续相同验证码错误达5次后,限制24小时后登录
  - 注意: 从第一次点击登录开始计时
  - toast: "您登陆失败的次数过得多, 请24小时后再想重试"
- 特殊



## 发送短信





# 用户创建行程订单

### 前置操作

1. 输入上车地点, 目的地
2. 预估价格(order-service->OrderController->forecast())

开始订单

1. 根据上车地叫车
2. 派单

整体的代码大概思路是: 

```java



//新建一个task类, 任务条件类taskCondition , taskCondition由派单规则和订单构成
//也就是可以将各种规则抽象成一个任务条件, 让任务根据任务条件去执行任务, 规则就是一个变化点, 即隔离变化点, 无论你规则怎么变, 始终都抽象成一个任务条件.
//任务的执行也可优化, , , 有各种各样的任务, 可以抽象...
task.setTaskConditions(taskConditions);
//执行任务, 
//1. 根据任务条件里的距离, 经纬度等信息找出派单的司机
//2. 给司机推送消息(极光), 发送短信给司机
int status = task.execute(System.currentTimeMillis());
//任务未结束将任务加入TaskStore, 派单任务已结束直接返回派单成功
if (status != -1) {
    taskStore.addTask(task.getTaskId(), task);
}
return ResponseResult.success("派单成功");

//之后的逻辑是
//1. 派单成功后, 司机接单, 成为正式订单
//2. 派单成功后, 但是没有司机接单, 
//定时任务, 继续进行更大范围的派单,     
//x轮后, 无司机接单, 提示无司机接单给用户
```

具体流程看派单逻辑图![image-20201130124027443](C:\Users\Administrator\AppData\Roaming\Typora\typora-user-images\image-20201130124027443.png)









# 发布新版本的方法

## 蓝绿发布

在旧版本服务器有几台, 就部署相同数量的新版本服务, 然后关闭旧版本

缺点: 需要多一倍的服务器资源, 费钱

## 滚动发布

部署好X数量的新版本服务器, 然后下线X台旧版本服务器, 再部署新版本, 一直滚动完成

缺点: 发布过程中, 会导致服务存在差异, 出错很难排查, 

## 灰度发布(金丝雀发布)

1. 指定灰度规则, 区分哪些用户走哪些服务



怎么做: 

第一种: 在eureka里自定义metadata元数据

第二种: 网关路由

```java
@Component
public class GrayFilter extends ZuulFilter {
	......
    @Override
    public Object run() throws ZuulException {
        RequestContext currentContext = RequestContext.getCurrentContext();
        HttpServletRequest request = currentContext.getRequest();

        int userId = Integer.parseInt(request.getHeader("userId"));
        // 根据用户id 查 规则  查库 v1,meata

        // 金丝雀
        if (userId == 1){
            RibbonFilterContextHolder.getCurrentContext().add("version","v1");
        }
        // 普通用户
        return null;
    }
}

//在需要灰度发布的服务上
eureka:
  instance:
    metadata-map:
      version: v2
//以上两步即可将需要的用户导向新版本, 其余用户依旧在原始版本
//可以将需要灰度的用户服务存入数据库
id  user_id  service_name  meta_version 
1	1		 service-sms   v1
```

第三种: ribbon实现

没看视频











# [分布式事务](https://juejin.cn/post/6844903734753886216)

## 相关文章

https://www.cnblogs.com/savorboard/p/distributed-system-transaction-consistency.html



本地事务

1. A：Atomic，原子性，将所有SQL作为原子工作单元执行，要么全部执行，要么全部不执行；
2. C：Consistent，一致性，事务完成后，所有数据的状态都是一致的，即A账户只要减去了100，B账户则必定加上了100；
3. I：Isolation，隔离性，如果有多个事务并发执行，每个事务作出的修改必须与其他事务隔离；
4. D：Duration，持久性，即事务完成后，对数据库数据的修改被持久化存储。

> AD是通过日志文件来保证的
>
>  如果日志有事务提交记录, 数据库没有, 执行redo操作, 没有commit, 执行undo
>
> CI是通过锁
>
> 

数据库本地事务是如何保证的?

答: 锁, redo , undo 



## 两阶段提交

XA 是一个两阶段提交协议，该协议分为以下两个阶段：

在两阶段提交中，主要涉及到两个角色，分别是协调者和参与者。

第一阶段：当要执行一个分布式事务的时候，事务发起者首先向协调者发起事务请求，然后协调者会给所有参与者发送 `prepare` 请求（其中包括事务内容）告诉参与者你们需要执行事务了，如果能执行我发的事务内容那么就先执行但不提交，执行后请给我回复。然后参与者收到 `prepare` 消息后，他们会开始执行事务（但不提交），并将 `Undo` 和 `Redo` 信息记入事务日志中，之后参与者就向协调者反馈是否准备好了。

第二阶段：第二阶段主要是协调者根据参与者反馈的情况来决定接下来是否可以进行事务的提交操作，即提交事务或者回滚事务。

> 比如这个时候 **所有的参与者** 都返回了准备好了的消息，这个时候就进行事务的提交，协调者此时会给所有的参与者发送 **`Commit` 请求** ，当参与者收到 `Commit` 请求的时候会执行前面执行的事务的 **提交操作** ，提交完毕之后将给协调者发送提交成功的响应。
>
> 而如果在第一阶段并不是所有参与者都返回了准备好了的消息，那么此时协调者将会给所有参与者发送 **回滚事务的 `rollback` 请求**，参与者收到之后将会 **回滚它在第一阶段所做的事务处理** ，然后再将处理情况返回给协调者，最终协调者收到响应后便给事务发起者返回处理失败的结果。



缺点:

- **单点故障问题**，如果协调者TM (transaction manager)挂了那么整个系统都处于不可用的状态了。
- **阻塞问题**，即当协调者发送 `prepare` 请求，参与者收到之后如果能处理那么它将会进行事务的处理但并不提交，这个时候会一直占用着**资源不释放**，如果此时协调者挂了，那么这些资源都不会再释放了，这会极大影响性能。
- **数据不一致问题**，比如当第二阶段，协调者只发送了一部分的 `commit` 请求就挂了，那么也就意味着，收到消息的参与者会进行事务的提交，而后面没收到的则不会进行事务提交，那么这时候就会产生数据不一致性问题。



## 三阶段提交

因为2PC存在的一系列问题，比如单点，容错机制缺陷等等，从而产生了 **3PC（三阶段提交）** 。那么这三阶段又分别是什么呢？

> 千万不要吧PC理解成个人电脑了，其实他们是 phase-commit 的缩写，即阶段提交。

1. **CanCommit阶段**：协调者向所有参与者发送 `CanCommit` 请求，参与者收到请求后会根据自身情况查看是否能执行事务，如果可以则返回 YES 响应并进入预备状态，否则返回 NO 。
2. **PreCommit阶段**：协调者根据参与者返回的响应来决定是否可以进行下面的 `PreCommit` 操作。如果上面参与者返回的都是 YES，那么协调者将向所有参与者发送 `PreCommit` 预提交请求，**参与者收到预提交请求后，会进行事务的执行操作，并将 `Undo` 和 `Redo` 信息写入事务日志中** ，最后如果参与者顺利执行了事务则给协调者返回成功的响应。如果在第一阶段协调者收到了 **任何一个 NO** 的信息，或者 **在一定时间内** 并没有收到全部的参与者的响应，那么就会中断事务，它会向所有参与者发送中断请求（abort），参与者收到中断请求之后会立即中断事务，或者在一定时间内没有收到协调者的请求，它也会中断事务。
3. **DoCommit阶段**：这个阶段其实和 `2PC` 的第二阶段差不多，如果协调者收到了所有参与者在 `PreCommit` 阶段的 YES 响应，那么协调者将会给所有参与者发送 `DoCommit` 请求，**参与者收到 `DoCommit` 请求后则会进行事务的提交工作**，完成后则会给协调者返回响应，协调者收到所有参与者返回的事务提交成功的响应之后则完成事务。若协调者在 `PreCommit` 阶段 **收到了任何一个 NO 或者在一定时间内没有收到所有参与者的响应** ，那么就会进行中断请求的发送，参与者收到中断请求后则会 **通过上面记录的回滚日志** 来进行事务的回滚操作，并向协调者反馈回滚状况，协调者收到参与者返回的消息后，中断事务。

> 协调者在指定时间内为收到全部的确认消息则进行事务中断的处理，这样能 **减少同步阻塞的时间** 。还有需要注意的是，**`3PC` 在 `DoCommit` 阶段参与者如未收到协调者发送的提交事务的请求，它会在一定时间内进行事务的提交**。为什么这么做呢？是因为这个时候我们肯定**保证了在第一阶段所有的协调者全部返回了可以执行事务的响应**，这个时候我们有理由**相信其他系统都能进行事务的执行和提交**，所以**不管**协调者有没有发消息给参与者，进入第三阶段参与者都会进行事务的提交操作。

`3PC` 通过一系列的超时机制很好的缓解了阻塞问题，但是最重要的一致性并没有得到根本的解决，比如在 `PreCommit` 阶段，当一个参与者收到了请求之后其他参与者和协调者挂了或者出现了网络分区，这个时候收到消息的参与者都会进行事务提交，这就会出现数据不一致性问题。

所以，要解决一致性问题还需要靠 `Paxos` 算法⭐️ ⭐️ ⭐️ 。



## paxos算法





## 还有其他分布式事务解决方案 

> 如: 2pc , 3pc, 消息队列+事件表, tcc, 可靠消息最终一致性, 最大努力通知
>
> 落地实现: 消息队列, seata



刚性事务

柔性事务

## 分布式事务解决方案: 消息队列+本地消息表

> **该方案不适用于数据量特别大的**

拿支付系统和订单系统来做示例

场景: 当第三方支付回调时, 支付系统支付流水记录做更新, 订单系统也进行订单表状态进行更新

1. 当第三方支付回调我们支付系统时, 更新支付信息, 并插入支付事件表(状态为自定义, 表示未发送到消息队列).

2. 将事件表发到消息队列(以下操作为原子操作, 本地事务保证)

   1. 定时任务查询事件表未发送队列记录
   2. 更新事件表为已发送到队列
   3. 发送给消息队列 (若入队失败, 回滚)

3. 订单系统监听消息队列, 插入订单事件表(以下操作为原子操作, 本地事务保证)

   1. 消息消费者监听消息队列

   2. 将事件插入订单事件表(状态为已接受)

   3. mq.ack()//我已成功处理该消息, 可丢弃

      ```java
      String msg = "消息来了";
      try{
          入库;
          mq.ack();
      }catch(execption e){
          mq.recovery();//下次还可以接着消费
      }
      ```

4. 读取订单事件表记录, 修改订单表信息(以下操作为原子操作, 本地事务保证)

   1. 定时任务读取订单事件表
   2. 执行订单支付成功业务
   3. 修改事件表为已处理

> 1. 如何避免消息重复消费: 入队时提供事件id, 来做主键约束, 来保证消息重复消费的问题
> 2. 定时任务可以采用哪些方式: task, schedule, quartz, scheduleExecute等等甚至linux cron

```java
//支付系统, 定时逻辑
import org.springframework.jms.core.JmsMessagingTemplate;
@Component
public class ProduceTask {

    @Autowired
    private TblOrderEventDao tblOrderEventDao;

    @Autowired
    private Queue queue;

    @Autowired
    JmsMessagingTemplate jmsMessagingTemplate;

    @Scheduled(cron="0/5 * * * * ?")
    @Transactional(rollbackFor = Exception.class)
    public void task(){
        System.out.println("定时任务");

        List<TblOrderEvent> tblOrderEventList = tblOrderEventDao.selectByOrderType("1");
        for (int i = 0; i < tblOrderEventList.size(); i++) {
            TblOrderEvent event = tblOrderEventList.get(i);

            // 更改这条数据的orderType为2
            tblOrderEventDao.updateEvent(event.getOrderType());
            System.out.println("修改数据库完成");

            jmsMessagingTemplate.convertAndSend(queue,JSONObject.fromObject(event).toString());
        }
    }
}
```

```java
//订单系统, 定时逻辑
@Component
public class ConsumerQueue {

    @Autowired
    private TblOrderEventDao tblOrderEventDao;

    @JmsListener(destination = "ActiveMQQueue",containerFactory = "jmsListenerContainerFactory")
    public void receive(TextMessage textMessage, Session session) throws JMSException {
        try {
            System.out.println("收到的消息："+textMessage.getText());
            String content = textMessage.getText();

            TblOrderEvent tblOrderEvent = (TblOrderEvent) JSONObject.toBean(JSONObject.fromObject(content),TblOrderEvent.class);
            tblOrderEventDao.insert(tblOrderEvent);
            // 业务完成，确认消息 消费成功
            //需在配置里开启客户端手动确认bean.setSessionAcknowledgeMode(2);
            textMessage.acknowledge();
        }catch (Exception e){
            // 回滚消息
            e.printStackTrace();
//            e.getMessage(); // 放到log中。
            System.out.println("异常了");
            session.recover();
        }
    }

    /**
     * 补偿 处理（人工，脚本）。自己根据自己情况。
     * @param text
     */
    @JmsListener(destination = "DLQ.ActiveMQQueue")
    public void receive2(String text){
        System.out.println("死信队列:"+text);
    }
}
```



## 分布式事务解决方案LCN（Lock Confirm notify）



## 分布式事务解决方案TCC（Try Confirm Cancel）



## 分布式事务解决方案-可靠消息服务-最大努力通知-事务消息



## 分布式事务解决方案RocketMQ 事务消息方案



## [分布式事务解决方案Seata AT模式](http://seata.io/zh-cn/docs/dev/mode/at-mode.html)



## [分布式事务解决方案Seata TCC模式](http://seata.io/zh-cn/docs/dev/mode/tcc-mode.html)

> 适用于没有ACID事务的数据库

TCC一些问题: 

- 空回滚

try未执行, cancel执行了

解决方案: 加事务控制表

{

tx_id(全局事务id),

branch_id(分支id),

status(1(事务初始化, 2(已提交), 3(已回滚)))

}

- 幂等

多次执行cancel, confirm

解决方案: 加事务控制表

- 悬挂

cancel在try之前

解决方案: 加事务控制表

cancel的时候, 新增一条记录, (如果原来没有记录, 执行空方法 , 在插入已回滚的记录, try执行的时候, 发现有记录, 空try)





## [分布式事务解决方案Seata SAGA模式](http://seata.io/zh-cn/docs/dev/mode/saga-mode.html)



## [分布式事务解决方案Seata XA模式](http://seata.io/zh-cn/docs/dev/mode/xa-mode.html)



# 分布式锁

### mysql锁

> (性能差, 比redis查10万倍)

每次lock的时候插入lock表一条记录, 使用主键冲突来判断是够拿到锁, 插入成功即拿到锁, 未拿到锁的线程, 不断tryLock(); 

拿到锁的线程执行完业务, unlock();(删除记录)

接着其他tryLock()的线程继续插入lock表一条记录

也就是全部的线程都会最终拿到一次锁, 

然后其他没拿到资源的线程, 将再次访问一遍资源, 判断资源未抢到. 释放锁



### 单机redis锁





# 抢单(秒杀)

前提: 已有的交易系统功能完善, 稳定, 短时间 , 高并发

从三个点答: 

- 准: 不多卖, 不少卖 (分布式锁)
- 快: 服务响应速度要快
- 稳: 服务的可用性

网络(转发) , CPU(并发), 内存(xxx), 硬盘(mysql)

提高并发 

- 可以使用分段锁, 将库存分段, 分X段就有X个锁, 一次有X个人抢到
- 请求量要少(接口数据少)
- 请求路径要短(减少链路)
- 动静分离(识别热点数据)
- cdn优化
- 削峰填谷(消息队列, 异步处理, 提高响应速度, )





# idea调试按钮意思

1. show execution point (Alt+F10): 显示当前执行代码的位置。
2. step over (F8): step to the next line in this file; 执行下一行代码。
3. step into (F7): step into the next line executed; 即当前代码是方法时，进入该方法；是赋值语句的话则效果跟step over 是一样的。
4. force step into (Alt+Shift+F7): ingore stepping filters for libraries, constructors etc. 忽略进入库的拦截器、构造器等。
5. step out (Shift+F8): step to the first line executed after returning from this method; 配合drop frame 使用：比如到达断点后已经执行了下一行或多行代码，点step out(就会进入下一个栈帧), 再点drop frame(就会继续进入下一个栈帧), 再点step out，就回到原断点了(第12行)。
6. drop frame: moves execution point back to the method call dropping current method frames from the stack; 把执行点移回到 从栈中弹出当前方法栈帧 的方法调用处，即回退到上一个调用的方法；用起来有点akward。
7. run to cursor (Alt+F9): run to the line where the caret(补字号) is; 执行到光标位置，此功能只能前进(位置应在当前位置之后)，而不能后退。
8. evaluate expression (Alt+F8): evaluate arbitrary expression; 弹出可输入计算表达式调试框。